{
 "cells": [
  {
   "cell_type": "code",
   "id": "8a83f5a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T01:46:12.773372Z",
     "start_time": "2024-09-27T01:46:11.431712Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from copy import deepcopy\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, mean_absolute_percentage_error\n",
    "import warnings\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "import time\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Import MLflow and DAGsHub\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import dagshub"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "mlflow-init",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T01:46:23.508824Z",
     "start_time": "2024-09-27T01:46:22.673473Z"
    }
   },
   "source": [
    "# Initialize DAGsHub and MLflow\n",
    "dagshub.init(url=\"https://github.com/JuanPab2009/ProyectoFinalCD.git\", mlflow=True)\n",
    "MLFLOW_TRACKING_URI = mlflow.get_tracking_uri()\n",
    "print(MLFLOW_TRACKING_URI)\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(experiment_name=\"LaLiga-prediction\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accessing as JuanPab2009\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as JuanPab2009\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Initialized MLflow to track repo \u001B[32m\"JuanPab2009/ProyectoFinalCD\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"JuanPab2009/ProyectoFinalCD\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Repository JuanPab2009/ProyectoFinalCD initialized!\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository JuanPab2009/ProyectoFinalCD initialized!\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/JuanPab2009/ProyectoFinalCD.mlflow\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "API request to endpoint /api/2.0/mlflow/experiments/get-by-name failed with error code 404 != 200. Response body: 'Not Found'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mMlflowException\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(MLFLOW_TRACKING_URI)\n\u001B[1;32m      6\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mset_tracking_uri(MLFLOW_TRACKING_URI)\n\u001B[0;32m----> 7\u001B[0m \u001B[43mmlflow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_experiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexperiment_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mLaLiga-prediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PCyD/ProyectoFinalCD/.venv/lib/python3.11/site-packages/mlflow/tracking/fluent.py:145\u001B[0m, in \u001B[0;36mset_experiment\u001B[0;34m(experiment_name, experiment_id)\u001B[0m\n\u001B[1;32m    143\u001B[0m client \u001B[38;5;241m=\u001B[39m MlflowClient()\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m experiment_id \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 145\u001B[0m     experiment \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_experiment_by_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexperiment_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m experiment:\n\u001B[1;32m    147\u001B[0m         _logger\u001B[38;5;241m.\u001B[39minfo(\n\u001B[1;32m    148\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExperiment with name \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m does not exist. Creating a new experiment.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    149\u001B[0m             experiment_name,\n\u001B[1;32m    150\u001B[0m         )\n",
      "File \u001B[0;32m~/Documents/PCyD/ProyectoFinalCD/.venv/lib/python3.11/site-packages/mlflow/tracking/client.py:1249\u001B[0m, in \u001B[0;36mMlflowClient.get_experiment_by_name\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1217\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_experiment_by_name\u001B[39m(\u001B[38;5;28mself\u001B[39m, name: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[Experiment]:\n\u001B[1;32m   1218\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Retrieve an experiment by experiment name from the backend store\u001B[39;00m\n\u001B[1;32m   1219\u001B[0m \n\u001B[1;32m   1220\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1247\u001B[0m \u001B[38;5;124;03m        Lifecycle_stage: active\u001B[39;00m\n\u001B[1;32m   1248\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1249\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tracking_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_experiment_by_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PCyD/ProyectoFinalCD/.venv/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py:484\u001B[0m, in \u001B[0;36mTrackingServiceClient.get_experiment_by_name\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    476\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_experiment_by_name\u001B[39m(\u001B[38;5;28mself\u001B[39m, name):\n\u001B[1;32m    477\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    478\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    479\u001B[0m \u001B[38;5;124;03m        name: The experiment name.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;124;03m        :py:class:`mlflow.entities.Experiment`\u001B[39;00m\n\u001B[1;32m    483\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 484\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_experiment_by_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PCyD/ProyectoFinalCD/.venv/lib/python3.11/site-packages/mlflow/store/tracking/rest_store.py:519\u001B[0m, in \u001B[0;36mRestStore.get_experiment_by_name\u001B[0;34m(self, experiment_name)\u001B[0m\n\u001B[1;32m    517\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    518\u001B[0m     req_body \u001B[38;5;241m=\u001B[39m message_to_json(GetExperimentByName(experiment_name\u001B[38;5;241m=\u001B[39mexperiment_name))\n\u001B[0;32m--> 519\u001B[0m     response_proto \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_endpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mGetExperimentByName\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreq_body\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Experiment\u001B[38;5;241m.\u001B[39mfrom_proto(response_proto\u001B[38;5;241m.\u001B[39mexperiment)\n\u001B[1;32m    521\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m MlflowException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/Documents/PCyD/ProyectoFinalCD/.venv/lib/python3.11/site-packages/mlflow/store/tracking/rest_store.py:82\u001B[0m, in \u001B[0;36mRestStore._call_endpoint\u001B[0;34m(self, api, json_body, endpoint)\u001B[0m\n\u001B[1;32m     80\u001B[0m     endpoint, method \u001B[38;5;241m=\u001B[39m _METHOD_TO_INFO[api]\n\u001B[1;32m     81\u001B[0m response_proto \u001B[38;5;241m=\u001B[39m api\u001B[38;5;241m.\u001B[39mResponse()\n\u001B[0;32m---> 82\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall_endpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_host_creds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_proto\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/PCyD/ProyectoFinalCD/.venv/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:370\u001B[0m, in \u001B[0;36mcall_endpoint\u001B[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001B[0m\n\u001B[1;32m    367\u001B[0m     call_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjson\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m json_body\n\u001B[1;32m    368\u001B[0m     response \u001B[38;5;241m=\u001B[39m http_request(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcall_kwargs)\n\u001B[0;32m--> 370\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mverify_rest_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendpoint\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    371\u001B[0m response_to_parse \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mtext\n\u001B[1;32m    372\u001B[0m js_dict \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(response_to_parse)\n",
      "File \u001B[0;32m~/Documents/PCyD/ProyectoFinalCD/.venv/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:246\u001B[0m, in \u001B[0;36mverify_rest_response\u001B[0;34m(response, endpoint)\u001B[0m\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    242\u001B[0m         base_msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    243\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAPI request to endpoint \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mendpoint\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    244\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfailed with error code \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m != 200\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    245\u001B[0m         )\n\u001B[0;32m--> 246\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n\u001B[1;32m    247\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbase_msg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Response body: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mtext\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    248\u001B[0m             error_code\u001B[38;5;241m=\u001B[39mget_error_code(response\u001B[38;5;241m.\u001B[39mstatus_code),\n\u001B[1;32m    249\u001B[0m         )\n\u001B[1;32m    251\u001B[0m \u001B[38;5;66;03m# Skip validation for endpoints (e.g. DBFS file-download API) which may return a non-JSON\u001B[39;00m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;66;03m# response\u001B[39;00m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m endpoint\u001B[38;5;241m.\u001B[39mstartswith(_REST_API_PATH_PREFIX) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _can_parse_as_json_object(response\u001B[38;5;241m.\u001B[39mtext):\n",
      "\u001B[0;31mMlflowException\u001B[0m: API request to endpoint /api/2.0/mlflow/experiments/get-by-name failed with error code 404 != 200. Response body: 'Not Found'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eec3bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('LaLiga Dataset 2023-2024.xlsx')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12a35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a4a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['Día','Sedes','Edad(opp)','Pos.(opp)', 'Ass(opp)', 'TPint(opp)', \n",
    "      'PrgC(opp)', 'PrgP(opp)','% de TT(opp)', 'Dist(opp)', '% Cmp(opp)', 'Dist. tot.(opp)','TklG(opp)', 'Int(opp)', \n",
    "      'Err(opp)', 'RL(opp)', 'PG(opp)', 'PE(opp)','PP(opp)', 'GF(opp)', 'GC(opp)', 'xG(opp)', 'xGA(opp)','Últimos 5(opp)', \n",
    "      'Máximo Goleador del Equipo(opp)', 'Edad(tm)', 'Pos.(tm)', 'Ass(tm)', 'TPint(tm)', 'PrgC(tm)', 'PrgP(tm)',\n",
    "      '% de TT(tm)', 'Dist(tm)', '% Cmp(tm)', 'Dist. tot.(tm)', 'TklG(tm)','Int(tm)', 'Err(tm)', 'RL(tm)', 'PG(tm)', \n",
    "      'PE(tm)', 'PP(tm)', 'GF(tm)','GC(tm)', 'xG(tm)', 'xGA(tm)', 'Últimos 5(tm)','Máximo Goleador del Equipo(tm)']]\n",
    "y=df['Resultado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4c70878",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26344119",
   "metadata": {},
   "source": [
    "### Regresión logística sin parámetros con MLflow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a22576",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Logistic Regression\"):\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    acc = logreg.score(X_test, y_test)\n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "    mlflow.log_params(logreg.get_params())\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    # Confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='.0f')\n",
    "    plt.xlabel(\"Predicted Digits\")\n",
    "    plt.ylabel(\"True Digits\")\n",
    "    plt.title('Logistic Regression')\n",
    "    plt.show()\n",
    "    # Save confusion matrix plot\n",
    "    plt.savefig(\"confusion_matrix_lr.png\")\n",
    "    mlflow.log_artifact(\"confusion_matrix_lr.png\")\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(logreg, \"model\")\n",
    "    # Get run ID\n",
    "    lr_run_id = mlflow.active_run().info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ed496",
   "metadata": {},
   "source": [
    "### Sobremuestreo y escalamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72d1f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res, y_train_res = X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e196f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68489a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_res = sc.fit_transform(X_train_res)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5578f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=n_folds, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1077cae",
   "metadata": {},
   "source": [
    "### Regresión logística con validación cruzada y MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73506b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Logistic Regression with CV\"):\n",
    "    # crear modelo\n",
    "    log_model = LogisticRegression()\n",
    "    #Hacer el cross validation y probar con el train\n",
    "    log_acc = cross_val_score(log_model, X_train_res, y_train_res, scoring='accuracy', cv=kfold)\n",
    "    log_prec = cross_val_score(log_model, X_train_res, y_train_res, scoring='precision_weighted', cv=kfold)\n",
    "    log_rec = cross_val_score(log_model, X_train_res, y_train_res, scoring='recall_weighted', cv=kfold)\n",
    "\n",
    "    # Performance\n",
    "    print('Accuracy: %.4f' % (np.mean(log_acc)))\n",
    "    print('Precision: %.4f' % (np.mean(log_prec)))\n",
    "    print('Recall: %.4f' % (np.mean(log_rec)))\n",
    "\n",
    "    # Entrenar modelo\n",
    "    log_model.fit(X_train_res, y_train_res)\n",
    "    y_pred = log_model.predict(X_test)\n",
    "\n",
    "    acc_lr=accuracy_score(y_test,y_pred)\n",
    "    prec_lr=precision_score(y_test,y_pred,average='weighted')\n",
    "    rec_lr=recall_score(y_test,y_pred,average='weighted')\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"LogisticRegression_CV\")\n",
    "    mlflow.log_params(log_model.get_params())\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", acc_lr)\n",
    "    mlflow.log_metric(\"precision\", prec_lr)\n",
    "    mlflow.log_metric(\"recall\", rec_lr)\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(log_model, \"model\")\n",
    "    # Get run ID\n",
    "    lr_cv_run_id = mlflow.active_run().info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f80a2d",
   "metadata": {},
   "source": [
    "# SVC con MLflow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b0da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"SVC\"):\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "    from scipy.stats import uniform\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=X_train_res.shape[1], whiten=True, random_state=42)\n",
    "    X_train_pca = pca.fit_transform(X_train_res)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # Inicializar modelo SVC\n",
    "    svc = SVC(kernel='rbf', class_weight='balanced')\n",
    "\n",
    "    # Definir los hiperparámetros para la búsqueda aleatoria\n",
    "    param_dist = {\n",
    "        'C': uniform(1, 50),  # Distribución uniforme de valores entre 1 y 50\n",
    "        'gamma': uniform(0.0001, 0.01)\n",
    "    }\n",
    "\n",
    "    # RandomizedSearchCV con búsqueda aleatoria\n",
    "    grid = RandomizedSearchCV(\n",
    "        svc,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=20,  # Realiza 20 búsquedas aleatorias\n",
    "        cv=3,  # Validación cruzada con 3 folds\n",
    "        n_jobs=-1,  # Utiliza todos los núcleos\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    grid.fit(X_train_pca, y_train_res)\n",
    "\n",
    "    # Imprimir los mejores hiperparámetros encontrados\n",
    "    print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
    "\n",
    "    # Creación del modelo con los parámetros óptimos\n",
    "    model_new_svc = grid.best_estimator_\n",
    "\n",
    "    # Predecir\n",
    "    yfit_svc = model_new_svc.predict(X_test_pca)\n",
    "\n",
    "    # Evaluación del modelo\n",
    "    yhat_svc = model_new_svc.predict(X_test_pca)\n",
    "    accu_svc = accuracy_score(y_test, yhat_svc)\n",
    "    prec_svc = precision_score(y_test, yhat_svc, average='weighted')\n",
    "    reca_svc = recall_score(y_test, yhat_svc, average='weighted')\n",
    "\n",
    "    print(f'Accuracy: {accu_svc:.3f}')\n",
    "    print(f'Precision: {prec_svc:.3f}')\n",
    "    print(f'Recall: {reca_svc:.3f}')\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"SVC\")\n",
    "    mlflow.log_params(grid.best_params_)\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accu_svc)\n",
    "    mlflow.log_metric(\"precision\", prec_svc)\n",
    "    mlflow.log_metric(\"recall\", reca_svc)\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model_new_svc, \"model\")\n",
    "    # Get run ID\n",
    "    svc_run_id = mlflow.active_run().info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42daa45",
   "metadata": {},
   "source": [
    "# RandomForest con MLflow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b3755",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"RandomForest\"):\n",
    "    #Usando cross validation y grid search\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    model = RandomForestClassifier(criterion='gini',\n",
    "                                   min_samples_leaf=2,\n",
    "                                   bootstrap=True,\n",
    "                                   oob_score=False,\n",
    "                                   random_state=42,\n",
    "                                   verbose=2)\n",
    "\n",
    "\n",
    "    #Grid search para optimizar hiperparámetros\n",
    "\n",
    "    gs = GridSearchCV(model,\n",
    "                      param_grid = {'max_depth': range(1, 11), #profundidad del árbol\n",
    "                                    'min_samples_split': range(1, 10, 2),\n",
    "                                    'n_estimators': range(1,15,2) #número de árboles\n",
    "                                    }, \n",
    "                      cv=kfold,\n",
    "                      scoring='accuracy'\n",
    "                      )\n",
    "\n",
    "\n",
    "    #entrenar modelo\n",
    "    gs.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "    #imprimir hiperparámetros óptimos\n",
    "    print(gs.best_params_)\n",
    "\n",
    "    new_model = RandomForestClassifier(n_estimators=gs.best_params_['n_estimators'],\n",
    "                                   criterion='gini',\n",
    "                                   max_depth=gs.best_params_['max_depth'],\n",
    "                                   min_samples_split=gs.best_params_['min_samples_split'],\n",
    "                                   min_samples_leaf=2,\n",
    "                                   bootstrap=True,\n",
    "                                   oob_score=False,\n",
    "                                   random_state=42,\n",
    "                                   verbose=2)\n",
    "\n",
    "    #entrenar nuevo modelo\n",
    "    new_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "    yhat_rf = new_model.predict(X_test)\n",
    "    accu_rf = accuracy_score(y_test,yhat_rf)\n",
    "    prec_rf = precision_score(y_test,yhat_rf,average='weighted')\n",
    "    reca_rf = recall_score(y_test,yhat_rf,average='weighted')\n",
    "    print('Accuracy\\t Precision\\t Recall\\n %0.3f\\t %0.3f\\t %0.3f'%(accu_rf,prec_rf,reca_rf))\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"RandomForest\")\n",
    "    mlflow.log_params(gs.best_params_)\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accu_rf)\n",
    "    mlflow.log_metric(\"precision\", prec_rf)\n",
    "    mlflow.log_metric(\"recall\", reca_rf)\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(new_model, \"model\")\n",
    "    # Get run ID\n",
    "    rf_run_id = mlflow.active_run().info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59e3f7b",
   "metadata": {},
   "source": [
    "### XGBoost con MLflow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e221dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"XGBoost\"):\n",
    "    import xgboost as xgb\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "    # Prepare the data in DMatrix format\n",
    "    dtrain = xgb.DMatrix(X_train_res, label=y_train_res-1)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test-1)\n",
    "\n",
    "    # Set parameters\n",
    "    params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': 3,\n",
    "        'gamma': 1,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 10,\n",
    "        'reg_lambda': 1,\n",
    "        'scale_pos_weight': 1,\n",
    "        'subsample': 0.9,\n",
    "        'colsample_bytree': 0.5,\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    modelo_xgb = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dtest, 'test')],\n",
    "        early_stopping_rounds=10,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    # Make predictions\n",
    "    yhat_xgb = modelo_xgb.predict(dtest)\n",
    "    yhat_xgb = yhat_xgb.argmax(axis=1)  # Convert probabilities to class predictions\n",
    "\n",
    "    # Evaluate the model\n",
    "    accu_xgb = accuracy_score(y_test-1, yhat_xgb)\n",
    "    prec_xgb = precision_score(y_test-1, yhat_xgb, average='weighted')\n",
    "    reca_xgb = recall_score(y_test-1, yhat_xgb, average='weighted')\n",
    "\n",
    "    print('Accuracy\\t Precision\\t Recall')\n",
    "    print(f'{accu_xgb:.3f}\\t\\t {prec_xgb:.3f}\\t\\t {reca_xgb:.3f}')\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"XGBoost\")\n",
    "    mlflow.log_params(params)\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accu_xgb)\n",
    "    mlflow.log_metric(\"precision\", prec_xgb)\n",
    "    mlflow.log_metric(\"recall\", reca_xgb)\n",
    "    # Log model\n",
    "    mlflow.xgboost.log_model(modelo_xgb, \"model\")\n",
    "    # Get run ID\n",
    "    xgb_run_id = mlflow.active_run().info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-selection",
   "metadata": {},
   "source": [
    "### Selección del mejor modelo y registro en MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "select-best-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar los modelos y seleccionar el mejor\n",
    "data_compar_cross = {\n",
    "    'Modelo': ['LR', 'SVC', 'RF', 'XGBoost'],\n",
    "    'Accuracy': [acc_lr, accu_svc, accu_rf, accu_xgb],\n",
    "    'Precision': [prec_lr, prec_svc, prec_rf, prec_xgb],\n",
    "    'Recall': [rec_lr, reca_svc, reca_rf, reca_xgb]\n",
    "}\n",
    "\n",
    "data_compar_cross = pd.DataFrame(data_compar_cross)\n",
    "print(data_compar_cross)\n",
    "\n",
    "# Supongamos que XGBoost es el mejor modelo\n",
    "best_run_id = xgb_run_id\n",
    "\n",
    "# Registrar el mejor modelo en MLflow Model Registry\n",
    "result = mlflow.register_model(f\"runs:/{best_run_id}/model\", \"LaLigaBestModel\")\n",
    "print(f\"Modelo registrado con nombre: {result.name}, versión: {result.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de las métricas de los modelos\n",
    "data_compar_cross.plot(x='Modelo', y=['Accuracy', 'Precision', 'Recall'], kind='bar')\n",
    "plt.title('Comparación de Modelos')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "end",
   "metadata": {},
   "source": [
    "### Fin del notebook con MLflow tracking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
