{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predicción de Resultados de Partidos de Fútbol en La Liga Española utilizando un Modelo XGBoost Optimizado y Desplegado en una Arquitectura de Microservicios**\n",
    "\n",
    "## **Resumen**\n",
    "\n",
    "Este trabajo presenta el desarrollo e implementación de un sistema integral para predecir los resultados de los partidos de fútbol de La Liga Española. Utilizando técnicas avanzadas de aprendizaje automático, específicamente un modelo XGBoost optimizado, y datos estadísticos detallados recopilados mediante web scraping de FBref, el sistema predice la probabilidad de victoria local, empate y victoria visitante.\n",
    "\n",
    "La arquitectura del sistema incluye un pipeline de entrenamiento orquestado con Prefect, el seguimiento de experimentos y gestión de modelos con MLflow, una API RESTful construida con FastAPI para servir el modelo y una interfaz de usuario interactiva desarrollada con Streamlit. La implementación se realiza mediante una arquitectura de microservicios contenerizada con Docker y orquestada con Docker Compose, asegurando escalabilidad, portabilidad y mantenibilidad.\n",
    "\n",
    "Los resultados demuestran la eficacia del modelo XGBoost para esta tarea, superando a otros modelos de referencia como Regresión Logística, SVC y Random Forest. Además, el flujo de trabajo de MLOps implementado garantiza la reproducibilidad y facilita futuras mejoras y actualizaciones del sistema.\n",
    "\n",
    "## **1. Introducción**\n",
    "\n",
    "La predicción de resultados de partidos de fútbol es un tema de gran interés para aficionados, analistas deportivos y casas de apuestas. Al ser un mercado con tanta incertidumbre, hace que esta tarea sea desafiante, ya que los resultados dependen de una amplia cantidad de variables.\n",
    "\n",
    "Normalmente, las predicciones se han basado en el conocimiento de expertos o en estadísticas básicas. Sin embargo, con el aprendizaje automático y la disponibilidad de grandes conjuntos de datos se han abierto nuevas posibilidades para desarrollar modelos predictivos más sofisticados y precisos.\n",
    "\n",
    "Este proyecto se centra en la construcción y despliegue de un modelo de aprendizaje automático para predecir los resultados de los partidos de La Liga Española. Utilizamos un modelo XGBoost, conocido por su alto rendimiento en tareas de clasificación, y datos estadísticos detallados extraídos de FBref, una fuente pública y confiable de estadísticas de fútbol.\n",
    "\n",
    "Además, implementamos un flujo de trabajo de MLOps utilizando herramientas como Prefect para la orquestación de tareas y MLflow para el seguimiento de experimentos y la gestión de modelos. El resultado es un sistema que se despliega en una arquitectura de microservicios contenerizada con Docker y orquestada con Docker Compose, lo que permite un acceso fácil y eficiente a las predicciones a través de una interfaz web desarrollada con Streamlit.\n",
    "\n",
    "## **2. Antecedentes**\n",
    "\n",
    "La aplicación del aprendizaje automático en el mundo deportivo ha sido objeto de investigación en los últimos años. Los datos utilizados en este proyecto fueron obtenidos de la página FBref (https://fbref.com/es/equipos), una fuente pública de estadísticas de fútbol que incluye información detallada sobre los equipos, jugadores, y partidos de varias ligas alrededor del mundo, incluyendo La Liga. A diferencia de datasets más estandarizados y conocidos en plataformas como Kaggle, estos datos fueron extraídos directamente a través de scraping web para poder utilizarlos en este proyecto. Este tipo de extracción permite una mayor flexibilidad, pero no cuenta con un historial previo de uso como otros datasets más conocidos.\n",
    "\n",
    "Una limitación común en muchos de estos estudios es la falta de un flujo de trabajo de MLOps robusto, lo que dificulta la reproducción de los resultados y la adaptación del modelo a nuevas temporadas o conjuntos de datos actualizados. Además, algunos trabajos se basan en conjuntos de datos estáticos y no aprovechan la posibilidad de extraer datos en tiempo real o actualizados periódicamente.\n",
    "\n",
    "Este proyecto se diferencia al incorporar las mejores prácticas de MLOps, utilizando herramientas modernas que facilitan el desarrollo, seguimiento y despliegue del modelo. Al extraer datos directamente de FBref, se garantiza el acceso a información actualizada y relevante para la temporada actual, permitiendo que el modelo se mantenga vigente y pueda adaptarse a cambios en el rendimiento de los equipos.\n",
    "\n",
    "## **3. Objetivos**\n",
    "\n",
    "### **3.1 Objetivo General**\n",
    "\n",
    "Desarrollar e implementar un sistema de aprendizaje automático para predecir los resultados de los partidos de La Liga Española, utilizando las mejores prácticas de MLOps y una arquitectura de microservicios contenerizada.\n",
    "\n",
    "### **3.2 Objetivos Específicos**\n",
    "\n",
    "- **Recolección de Datos:** Recopilar datos estadísticos detallados de los equipos de La Liga desde FBref mediante web scraping.\n",
    "\n",
    "- **Análisis Exploratorio de Datos (EDA):** Realizar un análisis exhaustivo de los datos para comprender su estructura, identificar patrones y seleccionar las características más relevantes.\n",
    "\n",
    "- **Preprocesamiento de Datos:** Limpiar y transformar los datos, incluyendo la codificación de variables categóricas, normalización de variables numéricas y manejo de valores faltantes.\n",
    "\n",
    "- **Entrenamiento y Evaluación de Modelos:** Entrenar y evaluar diferentes modelos de aprendizaje automático (Regresión Logística, SVC, Random Forest, XGBoost), utilizando cross validation y seguimiento de experimentos con MLflow.\n",
    "\n",
    "- **Optimización y Selección del Mejor Modelo:** Optimizar los hiperparámetros de los modelos utilizando Grid Search y seleccionamos el modelo con mejor rendimiento basado en accuracy.\n",
    "\n",
    "- **Registro y Gestión del Modelo:** Registrar el modelo seleccionado en MLflow Model Registry para facilitar su gestión y despliegue.\n",
    "\n",
    "- **Orquestación del Pipeline de Entrenamiento:** Implementar un pipeline automatizado utilizando Prefect para orquestar las tareas de extracción, preprocesamiento, entrenamiento y registro del modelo.\n",
    "\n",
    "- **Desarrollo de API y Frontend:** Construir una API RESTful con FastAPI para servir el modelo, y desarrollar una interfaz gráfica de usuario con Streamlit para facilitar la interacción con el sistema.\n",
    "\n",
    "- **Contenerización y Despliegue:** Contenerizar la aplicación utilizando Docker y orquestar su despliegue con Docker Compose, garantizando escalabilidad y portabilidad.\n",
    "\n",
    "## **4. Planteamiento del Problema**\n",
    "\n",
    "El objetivo es predecir las probabilidades de un partido de La Liga (victoria local, empate o victoria visitante) basándose en datos estadísticos de los equipos involucrados. Dado un conjunto de variables predictoras que incluyen estadísticas de rendimiento, información histórica y características del equipo y los jugadores, se busca desarrollar un modelo que pueda predecir con precisión el resultado de un partido.\n",
    "\n",
    "Las variables consideradas incluyen:\n",
    "\n",
    "- **Estadísticas de Rendimiento del Equipo Local y Visitante:**\n",
    "\n",
    "  - Goles a favor y en contra.\n",
    "  - Goles esperados a favor y en contra (xG, xGA).\n",
    "  - Posesión promedio.\n",
    "  - Tiros totales y tiros a puerta.\n",
    "  - Pases completados, intentados y porcentaje de acierto.\n",
    "  - Clasificación en la liga.\n",
    "  - Resultados de los últimos partidos.\n",
    "  - Información sobre el máximo goleador.\n",
    "\n",
    "- **Variables Categóricas:**\n",
    "\n",
    "  - Día de la semana del partido.\n",
    "  - Sede (local o visitante).\n",
    "\n",
    "\n",
    "## **5. Metodología**\n",
    "\n",
    "### **5.1 Recolección de Datos**\n",
    "\n",
    "Se implementó un script de web scraping en Python utilizando la biblioteca `pandas` para extraer datos de FBref. El script recupera las diferentes tablas de FBref y nosotros implementamos toda la limpieza y manipulación de datos para crear el dataset final.\n",
    "\n",
    "Los datos se extraen para cada jornada y se almacenan en archivos CSV. Esto nos permite actualizar los datos periódicamente y mantener el modelo entrenado con información reciente.\n",
    "\n",
    "### **5.2 Análisis Exploratorio de Datos (EDA)**\n",
    "\n",
    "Se realizó un análisis exploratorio de datos para comprender la distribución y características de las variables recopiladas. Se utilizaron herramientas como gráficos de dispersión, histogramas y matrices de correlación para identificar relaciones entre variables y detectar posibles valores atípicos o inconsistencias.\n",
    "\n",
    "El EDA ayudó a identificar las características más relevantes para la predicción y a comprender la necesidad de transformaciones adicionales en los datos.\n",
    "\n",
    "### **5.3 Preprocesamiento de Datos**\n",
    "\n",
    "El preprocesamiento incluyó los siguientes pasos:\n",
    "\n",
    "- **Limpieza de Datos:** Manejo de valores faltantes mediante eliminación o imputación, y corrección de inconsistencias en los datos.\n",
    "\n",
    "- **Codificación de Variables Categóricas:** Transformación de variables categóricas (día de la semana, sede) en variables numéricas utilizando técnicas como Ordinal Encoding.\n",
    "\n",
    "- **Generación de Características:** Creación de nuevas características combinando información del equipo local y visitante para cada partido.\n",
    "\n",
    "- **Escalamiento de Variables Numéricas:** Normalización de variables numéricas utilizando `StandardScaler` para garantizar que todas las variables contribuyan de manera equitativa al entrenamiento del modelo.\n",
    "\n",
    "- **División de Datos:** Separación del conjunto de datos en conjuntos de entrenamiento (80%) y prueba (20%) utilizando `train_test_split`.\n",
    "\n",
    "### **5.4 Entrenamiento del Modelo**\n",
    "\n",
    "Se entrenaron y evaluaron varios modelos de clasificación:\n",
    "\n",
    "- **Regresión Logística:** Modelo lineal básico para clasificación multiclase.\n",
    "\n",
    "- **Máquinas de Vectores de Soporte (SVC):** Modelo basado en SVM con kernel RBF. Se utilizó `GridSearchCV` para optimizar los hiperparámetros `C` y `gamma`.\n",
    "\n",
    "- **Random Forest:** Modelo basado en árboles de decisión. Se utilizó `GridSearchCV` para optimizar hiperparámetros como `max_depth`, `min_samples_split` y `n_estimators`.\n",
    "\n",
    "- **XGBoost:** Modelo de boosting de gradiente. Se realizó una búsqueda exhaustiva de hiperparámetros para optimizar `n_estimators`, `max_depth`, `learning_rate`, `subsample` y `colsample_bytree`, entre otros.\n",
    "\n",
    "Para cada modelo, se registraron los parámetros y métricas utilizando MLflow, facilitando la comparación y selección del mejor modelo.\n",
    "\n",
    "### **5.5 Seguimiento con MLflow**\n",
    "\n",
    "MLflow se utilizó para el seguimiento de experimentos y la gestión de modelos. Cada experimento registró:\n",
    "\n",
    "- Parámetros del modelo.\n",
    "- Métricas de evaluación (Accuracy y recall).\n",
    "- Versiones del código y del entorno de ejecución.\n",
    "\n",
    "Esta práctica garantiza la reproducibilidad y facilita el análisis de los resultados obtenidos por cada modelo.\n",
    "\n",
    "### **5.6 Selección y Registro del Modelo**\n",
    "\n",
    "El modelo XGBoost mostró el mejor rendimiento en términos de precisión y otras métricas de evaluación. Se seleccionó como el modelo final y se registró en MLflow Model Registry con el nombre \"LaLigaBestModel\".\n",
    "\n",
    "El registro del modelo incluye información sobre la versión, el autor, las métricas de rendimiento y los parámetros utilizados, lo que facilita su despliegue y futuras actualizaciones.\n",
    "\n",
    "### **5.7 Orquestación del Pipeline**\n",
    "\n",
    "Se utilizó Prefect para orquestar el pipeline de entrenamiento, que incluye las siguientes tareas:\n",
    "\n",
    "- **Actualización del dataset:** Ejecuta las tareas de obtención, limpieza y transformación de datos para tener la versión más reciente de los resultados.\n",
    "\n",
    "- **Datos para predicción:** Ejecuta las tareas de obtención, limpieza y transformación de datos para hacer la predicción de una jornada.\n",
    "\n",
    "- **Cargar datos para predicción:** Se separan los datos de entrenamiento y prueba y se escalan los datos.\n",
    "\n",
    "- **Selección de hiperparámetros:** Se utiliza gridsearch con el modelo XGBoost en donde se generan múltiples runs y se obtienen los mejores parámetros.\n",
    "\n",
    "- **Entrenamiento del Modelo:** Entrenamiento de los modelos y registro de experimentos en MLflow con los mejores hiperparámetros.\n",
    "\n",
    "- **Selección y Registro del Mejor Modelo:** Automatización de la selección del modelo con mejor rendimiento y su registro en MLflow Model Registry.\n",
    "\n",
    "El uso de Prefect permite programar y monitorizar el pipeline, asegurando la reproducibilidad y facilitando la actualización del modelo con nuevos datos.\n",
    "\n",
    "### **5.8 API con FastAPI**\n",
    "\n",
    "Se desarrolló una API RESTful utilizando FastAPI para servir el modelo registrado en MLflow Model Registry. La API expone un endpoint `/predict` que:\n",
    "\n",
    "- Recibe como entrada la jornada para la cual se desean obtener predicciones.\n",
    "- Extrae los datos correspondientes a esa jornada.\n",
    "- Preprocesa los datos utilizando las mismas transformaciones aplicadas durante el entrenamiento.\n",
    "- Utiliza el modelo XGBoost para predecir el resultado de cada partido.\n",
    "- Devuelve las predicciones, incluyendo las probabilidades de cada posible resultado (victoria local, empate, victoria visitante).\n",
    "\n",
    "### **5.9 Interfaz Gráfica con Streamlit**\n",
    "\n",
    "Se desarrolló una interfaz de usuario interactiva con Streamlit que permite:\n",
    "\n",
    "- Seleccionar la jornada para la cual se desean obtener predicciones.\n",
    "- Visualizar los partidos de la jornada y las predicciones del modelo en un formato amigable.\n",
    "\n",
    "La interfaz facilita la interacción con el sistema para usuarios sin conocimientos técnicos, mejorando la accesibilidad del modelo.\n",
    "\n",
    "### **5.10 Contenerización con Docker**\n",
    "\n",
    "Se crearon Dockerfiles para contenerizar:\n",
    "\n",
    "- **API FastAPI:** Incluye el servidor de la API y todas sus dependencias.\n",
    "\n",
    "- **Aplicación Streamlit:** Incluye la interfaz de usuario y sus dependencias.\n",
    "\n",
    "La contenerización asegura que el sistema se pueda desplegar de manera consistente en diferentes entornos, resolviendo problemas de compatibilidad y dependencias.\n",
    "\n",
    "### **5.11 Despliegue con Docker Compose**\n",
    "\n",
    "Se utilizó Docker Compose para orquestar el despliegue de los microservicios:\n",
    "\n",
    "- Definición de los servicios de la API y la interfaz.\n",
    "- Configuración de una red compartida para permitir la comunicación entre los servicios.\n",
    "- Facilitación del despliegue y escalado del sistema.\n",
    "\n",
    "Este enfoque permite desplegar el sistema completo con un solo comando, simplificando la puesta en producción y el mantenimiento.\n",
    "\n",
    "## **6. Resultados**\n",
    "\n",
    "El modelo XGBoost entrenado alcanzó una precisión del **84%** en el conjunto de prueba, superando a los otros modelos evaluados. A continuación se presenta la métrica de nustro mejor modelo\n",
    "\n",
    "**Matriz de Confusión del Modelo XGBoost:**\n",
    "\n",
    "\n",
    "IMAGEN PENDIENTE\n",
    "\n",
    "Los resultados indican que el modelo XGBoost tiene una alta capacidad para distinguir entre las tres clases de resultados, con mejoras significativas en comparación con los modelos de referencia.\n",
    "\n",
    "Además, las probabilidades estimadas por el modelo permiten entender la confianza en cada predicción, lo cual es valioso para aplicaciones prácticas como análisis deportivos o decisiones de apuestas.\n",
    "\n",
    "## **7. Conclusiones**\n",
    "\n",
    "Este proyecto demuestra la eficacia de utilizar un modelo XGBoost optimizado para predecir los resultados de los partidos de La Liga Española. La integración de herramientas de MLOps como Prefect y MLflow facilitó el desarrollo, seguimiento y despliegue del modelo, garantizando reproducibilidad y mantenibilidad.\n",
    "\n",
    "La arquitectura de microservicios contenerizada y orquestada con Docker Compose proporciona un sistema escalable y portátil, que puede ser desplegado en diferentes entornos con facilidad. La interfaz de usuario desarrollada con Streamlit permite que los usuarios no técnicos interactúen con el modelo y exploren las predicciones.\n",
    "\n",
    "Durante el desarrollo, tuvimos diferentes problemas que logramos resolver. Tuvimos problemas con el training pipeline al implementar el flujo de trabajo; la orquestación de tareas con Prefect requirió de diversos intentos para asegurar que todas las etapas—desde la actualización del dataset y preprocesamiento de datos hasta el entrenamiento y registro del modelo—funcionaran de manera cohesiva. Además, en el backend, encontramos complicaciones al importar el modelo champion desde MLflow. Tuvimos que intentar de diferentes maneras desde el alias del champion hasta el run_id y al final fue esta última que nos ayudó a resolver el problema.\n",
    "\n",
    "Estas experiencias resaltan la importancia de anticipar y planificar para posibles desafíos al trabajar con pipelines complejos y sistemas de gestión de modelos. También nos proporcionan oportunidades para mejorar en futuros proyectos, optimizando los procesos y fortaleciendo la integración entre herramientas.\n",
    "\n",
    "Sin embargo, existen limitaciones que podrían abordarse en trabajos futuros, como la incorporación de datos adicionales (lesiones de jugadores, condiciones climáticas, análisis de sentimiento en redes sociales) que podrían mejorar aún más la precisión del modelo.\n",
    "\n",
    "## **8. Mejoras a Futuro**\n",
    "\n",
    "- **Incorporación de Datos Adicionales:** Agregar variables que capturen factores externos al rendimiento estadístico, como información sobre lesiones, suspensiones, condiciones climáticas y eventos especiales.\n",
    "\n",
    "- **Mejora del Modelo:** Explorar modelos más avanzados, como redes neuronales profundas o modelos híbridos que combinen aprendizaje automático con análisis estadístico tradicional.\n",
    "\n",
    "- **Análisis en Tiempo Real:** Adaptar el sistema para incorporar datos en tiempo real, permitiendo actualizaciones más frecuentes y predicciones más precisas.\n",
    "\n",
    "- **Implementación en la Nube:** Desplegar el sistema en plataformas de nube como AWS, Azure o Google Cloud, aprovechando servicios como Kubernetes para una gestión más avanzada de los contenedores.\n",
    "\n",
    "- **Optimización de la Interfaz de Usuario:** Mejorar la interfaz gráfica para incluir más visualizaciones interactivas y opciones de personalización.\n",
    "\n",
    "- **Integración Continua y Despliegue Continuo (CI/CD):** Implementar pipelines de CI/CD para automatizar las pruebas, el despliegue y las actualizaciones del sistema.\n",
    "\n",
    "\n",
    "\n",
    "## **9. Fuentes**\n",
    "\n",
    "1. **FBref:** [https://fbref.com/es/comps/12/La-Liga-Stats](https://fbref.com/es/comps/12/La-Liga-Stats)\n",
    "\n",
    "2. **Documentación de XGBoost:** [https://xgboost.readthedocs.io/](https://xgboost.readthedocs.io/)\n",
    "\n",
    "3. **Documentación de MLflow:** [https://mlflow.org/docs/latest/index.html](https://mlflow.org/docs/latest/index.html)\n",
    "\n",
    "4. **Documentación de Prefect:** [https://docs.prefect.io/](https://docs.prefect.io/)\n",
    "\n",
    "5. **Documentación de FastAPI:** [https://fastapi.tiangolo.com/es/](https://fastapi.tiangolo.com/es/)\n",
    "\n",
    "6. **Documentación de Streamlit:** [https://docs.streamlit.io/](https://docs.streamlit.io/)\n",
    "\n",
    "7. **Documentación de Docker:** [https://docs.docker.com/](https://docs.docker.com/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predicción de Resultados de Partidos de Fútbol en La Liga Española utilizando un Modelo XGBoost Optimizado y Desplegado en una Arquitectura de Microservicios**\n",
    "\n",
    "## **Resumen**\n",
    "\n",
    "Este trabajo presenta el desarrollo e implementación de un sistema integral para predecir los resultados de los partidos de fútbol de La Liga Española. Utilizando técnicas avanzadas de aprendizaje automático, específicamente un modelo XGBoost optimizado, y datos estadísticos detallados recopilados mediante web scraping de FBref, el sistema predice la probabilidad de victoria local, empate y victoria visitante.\n",
    "\n",
    "La arquitectura del sistema incluye un pipeline de entrenamiento orquestado con Prefect, el seguimiento de experimentos y gestión de modelos con MLflow, una API RESTful construida con FastAPI para servir el modelo y una interfaz de usuario interactiva desarrollada con Streamlit. La implementación se realiza mediante una arquitectura de microservicios contenerizada con Docker y orquestada con Docker Compose, asegurando escalabilidad, portabilidad y mantenibilidad.\n",
    "\n",
    "Los resultados demuestran la eficacia del modelo XGBoost para esta tarea, superando a otros modelos de referencia como Regresión Logística, SVC y Random Forest. Además, el flujo de trabajo de MLOps implementado garantiza la reproducibilidad y facilita futuras mejoras y actualizaciones del sistema.\n",
    "\n",
    "## **1. Introducción**\n",
    "\n",
    "La predicción de resultados de partidos de fútbol es un tema de gran interés para aficionados, analistas deportivos y casas de apuestas. Al ser un mercado con tanta incertidumbre, hace que esta tarea sea desafiante, ya que los resultados dependen de una amplia cantidad de variables.\n",
    "\n",
    "Normalmente, las predicciones se han basado en el conocimiento de expertos o en estadísticas básicas. Sin embargo, con el aprendizaje automático y la disponibilidad de grandes conjuntos de datos se han abierto nuevas posibilidades para desarrollar modelos predictivos más sofisticados y precisos.\n",
    "\n",
    "Este proyecto se centra en la construcción y despliegue de un modelo de aprendizaje automático para predecir los resultados de los partidos de La Liga Española. Utilizamos un modelo XGBoost, conocido por su alto rendimiento en tareas de clasificación, y datos estadísticos detallados extraídos de FBref, una fuente pública y confiable de estadísticas de fútbol.\n",
    "\n",
    "Además, implementamos un flujo de trabajo de MLOps utilizando herramientas como Prefect para la orquestación de tareas y MLflow para el seguimiento de experimentos y la gestión de modelos. El resultado es un sistema que se despliega en una arquitectura de microservicios contenerizada con Docker y orquestada con Docker Compose, lo que permite un acceso fácil y eficiente a las predicciones a través de una interfaz web desarrollada con Streamlit.\n",
    "\n",
    "## **2. Antecedentes**\n",
    "\n",
    "La aplicación del aprendizaje automático en el mundo deportivo ha sido objeto de investigación en los últimos años. Los datos utilizados en este proyecto fueron obtenidos de la página FBref (https://fbref.com/es/equipos), una fuente pública de estadísticas de fútbol que incluye información detallada sobre los equipos, jugadores, y partidos de varias ligas alrededor del mundo, incluyendo La Liga. A diferencia de datasets más estandarizados y conocidos en plataformas como Kaggle, estos datos fueron extraídos directamente a través de scraping web para poder utilizarlos en este proyecto. Este tipo de extracción permite una mayor flexibilidad, pero no cuenta con un historial previo de uso como otros datasets más conocidos.\n",
    "\n",
    "Una limitación común en muchos de estos estudios es la falta de un flujo de trabajo de MLOps robusto, lo que dificulta la reproducción de los resultados y la adaptación del modelo a nuevas temporadas o conjuntos de datos actualizados. Además, algunos trabajos se basan en conjuntos de datos estáticos y no aprovechan la posibilidad de extraer datos en tiempo real o actualizados periódicamente.\n",
    "\n",
    "Este proyecto se diferencia al incorporar las mejores prácticas de MLOps, utilizando herramientas modernas que facilitan el desarrollo, seguimiento y despliegue del modelo. Al extraer datos directamente de FBref, se garantiza el acceso a información actualizada y relevante para la temporada actual, permitiendo que el modelo se mantenga vigente y pueda adaptarse a cambios en el rendimiento de los equipos.\n",
    "\n",
    "## **3. Objetivos**\n",
    "\n",
    "### **3.1 Objetivo General**\n",
    "\n",
    "Desarrollar e implementar un sistema de aprendizaje automático para predecir los resultados de los partidos de La Liga Española, utilizando las mejores prácticas de MLOps y una arquitectura de microservicios contenerizada.\n",
    "\n",
    "### **3.2 Objetivos Específicos**\n",
    "\n",
    "- **Recolección de Datos:** Recopilar datos estadísticos detallados de los equipos de La Liga desde FBref mediante web scraping.\n",
    "\n",
    "- **Análisis Exploratorio de Datos (EDA):** Realizar un análisis exhaustivo de los datos para comprender su estructura, identificar patrones y seleccionar las características más relevantes.\n",
    "\n",
    "- **Preprocesamiento de Datos:** Limpiar y transformar los datos, incluyendo la codificación de variables categóricas, normalización de variables numéricas y manejo de valores faltantes.\n",
    "\n",
    "- **Entrenamiento y Evaluación de Modelos:** Entrenar y evaluar diferentes modelos de aprendizaje automático (Regresión Logística, SVC, Random Forest, XGBoost), utilizando cross validation y seguimiento de experimentos con MLflow.\n",
    "\n",
    "- **Optimización y Selección del Mejor Modelo:** Optimizar los hiperparámetros de los modelos utilizando Grid Search y seleccionamos el modelo con mejor rendimiento basado en accuracy.\n",
    "\n",
    "- **Registro y Gestión del Modelo:** Registrar el modelo seleccionado en MLflow Model Registry para facilitar su gestión y despliegue.\n",
    "\n",
    "- **Orquestación del Pipeline de Entrenamiento:** Implementar un pipeline automatizado utilizando Prefect para orquestar las tareas de extracción, preprocesamiento, entrenamiento y registro del modelo.\n",
    "\n",
    "- **Desarrollo de API y Frontend:** Construir una API RESTful con FastAPI para servir el modelo, y desarrollar una interfaz gráfica de usuario con Streamlit para facilitar la interacción con el sistema.\n",
    "\n",
    "- **Contenerización y Despliegue:** Contenerizar la aplicación utilizando Docker y orquestar su despliegue con Docker Compose, garantizando escalabilidad y portabilidad.\n",
    "\n",
    "## **4. Planteamiento del Problema**\n",
    "\n",
    "El objetivo es predecir las probabilidades de un partido de La Liga (victoria local, empate o victoria visitante) basándose en datos estadísticos de los equipos involucrados. Dado un conjunto de variables predictoras que incluyen estadísticas de rendimiento, información histórica y características del equipo y los jugadores, se busca desarrollar un modelo que pueda predecir con precisión el resultado de un partido.\n",
    "\n",
    "Las variables consideradas incluyen:\n",
    "\n",
    "- **Estadísticas de Rendimiento del Equipo Local y Visitante:**\n",
    "\n",
    "  - Goles a favor y en contra.\n",
    "  - Goles esperados a favor y en contra (xG, xGA).\n",
    "  - Posesión promedio.\n",
    "  - Tiros totales y tiros a puerta.\n",
    "  - Pases completados, intentados y porcentaje de acierto.\n",
    "  - Clasificación en la liga.\n",
    "  - Resultados de los últimos partidos.\n",
    "  - Información sobre el máximo goleador.\n",
    "\n",
    "- **Variables Categóricas:**\n",
    "\n",
    "  - Día de la semana del partido.\n",
    "  - Sede (local o visitante).\n",
    "\n",
    "\n",
    "## **5. Metodología**\n",
    "\n",
    "### **5.1 Recolección de Datos**\n",
    "\n",
    "Se implementó un script de web scraping en Python utilizando la biblioteca `pandas` para extraer datos de FBref. El script recupera las diferentes tablas de FBref y nosotros implementamos toda la limpieza y manipulación de datos para crear el dataset final.\n",
    "\n",
    "Los datos se extraen para cada jornada y se almacenan en archivos CSV. Esto nos permite actualizar los datos periódicamente y mantener el modelo entrenado con información reciente.\n",
    "\n",
    "### **5.2 Análisis Exploratorio de Datos (EDA)**\n",
    "\n",
    "Se realizó un análisis exploratorio de datos para comprender la distribución y características de las variables recopiladas. Se utilizaron herramientas como gráficos de dispersión, histogramas y matrices de correlación para identificar relaciones entre variables y detectar posibles valores atípicos o inconsistencias.\n",
    "\n",
    "El EDA ayudó a identificar las características más relevantes para la predicción y a comprender la necesidad de transformaciones adicionales en los datos.\n",
    "\n",
    "### **5.3 Preprocesamiento de Datos**\n",
    "\n",
    "El preprocesamiento incluyó los siguientes pasos:\n",
    "\n",
    "- **Limpieza de Datos:** Manejo de valores faltantes mediante eliminación o imputación, y corrección de inconsistencias en los datos.\n",
    "\n",
    "- **Codificación de Variables Categóricas:** Transformación de variables categóricas (día de la semana, sede) en variables numéricas utilizando técnicas como Ordinal Encoding.\n",
    "\n",
    "- **Generación de Características:** Creación de nuevas características combinando información del equipo local y visitante para cada partido.\n",
    "\n",
    "- **Escalamiento de Variables Numéricas:** Normalización de variables numéricas utilizando `StandardScaler` para garantizar que todas las variables contribuyan de manera equitativa al entrenamiento del modelo.\n",
    "\n",
    "- **División de Datos:** Separación del conjunto de datos en conjuntos de entrenamiento (80%) y prueba (20%) utilizando `train_test_split`.\n",
    "\n",
    "### **5.4 Entrenamiento del Modelo**\n",
    "\n",
    "Se entrenaron y evaluaron varios modelos de clasificación:\n",
    "\n",
    "- **Regresión Logística:** Modelo lineal básico para clasificación multiclase.\n",
    "\n",
    "- **Máquinas de Vectores de Soporte (SVC):** Modelo basado en SVM con kernel RBF. Se utilizó `GridSearchCV` para optimizar los hiperparámetros `C` y `gamma`.\n",
    "\n",
    "- **Random Forest:** Modelo basado en árboles de decisión. Se utilizó `GridSearchCV` para optimizar hiperparámetros como `max_depth`, `min_samples_split` y `n_estimators`.\n",
    "\n",
    "- **XGBoost:** Modelo de boosting de gradiente. Se realizó una búsqueda exhaustiva de hiperparámetros para optimizar `n_estimators`, `max_depth`, `learning_rate`, `subsample` y `colsample_bytree`, entre otros.\n",
    "\n",
    "Para cada modelo, se registraron los parámetros y métricas utilizando MLflow, facilitando la comparación y selección del mejor modelo.\n",
    "\n",
    "### **5.5 Seguimiento con MLflow**\n",
    "\n",
    "MLflow se utilizó para el seguimiento de experimentos y la gestión de modelos. Cada experimento registró:\n",
    "\n",
    "- Parámetros del modelo.\n",
    "- Métricas de evaluación (Accuracy y recall).\n",
    "- Versiones del código y del entorno de ejecución.\n",
    "\n",
    "Esta práctica garantiza la reproducibilidad y facilita el análisis de los resultados obtenidos por cada modelo.\n",
    "\n",
    "### **5.6 Selección y Registro del Modelo**\n",
    "\n",
    "El modelo XGBoost mostró el mejor rendimiento en términos de precisión y otras métricas de evaluación. Se seleccionó como el modelo final y se registró en MLflow Model Registry con el nombre \"LaLigaBestModel\".\n",
    "\n",
    "El registro del modelo incluye información sobre la versión, el autor, las métricas de rendimiento y los parámetros utilizados, lo que facilita su despliegue y futuras actualizaciones.\n",
    "\n",
    "### **5.7 Orquestación del Pipeline**\n",
    "\n",
    "Se utilizó Prefect para orquestar el pipeline de entrenamiento, que incluye las siguientes tareas:\n",
    "\n",
    "- **Actualización del dataset:** Ejecuta las tareas de obtención, limpieza y transformación de datos para tener la versión más reciente de los resultados.\n",
    "\n",
    "- **Datos para predicción:** Ejecuta las tareas de obtención, limpieza y transformación de datos para hacer la predicción de una jornada.\n",
    "\n",
    "- **Cargar datos para predicción:** Se separan los datos de entrenamiento y prueba y se escalan los datos.\n",
    "\n",
    "- **Selección de hiperparámetros:** Se utiliza gridsearch con el modelo XGBoost en donde se generan múltiples runs y se obtienen los mejores parámetros.\n",
    "\n",
    "- **Entrenamiento del Modelo:** Entrenamiento de los modelos y registro de experimentos en MLflow con los mejores hiperparámetros.\n",
    "\n",
    "- **Selección y Registro del Mejor Modelo:** Automatización de la selección del modelo con mejor rendimiento y su registro en MLflow Model Registry.\n",
    "\n",
    "El uso de Prefect permite programar y monitorizar el pipeline, asegurando la reproducibilidad y facilitando la actualización del modelo con nuevos datos.\n",
    "\n",
    "### **5.8 API con FastAPI**\n",
    "\n",
    "Se desarrolló una API RESTful utilizando FastAPI para servir el modelo registrado en MLflow Model Registry. La API expone un endpoint `/predict` que:\n",
    "\n",
    "- Recibe como entrada la jornada para la cual se desean obtener predicciones.\n",
    "- Extrae los datos correspondientes a esa jornada.\n",
    "- Preprocesa los datos utilizando las mismas transformaciones aplicadas durante el entrenamiento.\n",
    "- Utiliza el modelo XGBoost para predecir el resultado de cada partido.\n",
    "- Devuelve las predicciones, incluyendo las probabilidades de cada posible resultado (victoria local, empate, victoria visitante).\n",
    "\n",
    "### **5.9 Interfaz Gráfica con Streamlit**\n",
    "\n",
    "Se desarrolló una interfaz de usuario interactiva con Streamlit que permite:\n",
    "\n",
    "- Seleccionar la jornada para la cual se desean obtener predicciones.\n",
    "- Visualizar los partidos de la jornada y las predicciones del modelo en un formato amigable.\n",
    "\n",
    "La interfaz facilita la interacción con el sistema para usuarios sin conocimientos técnicos, mejorando la accesibilidad del modelo.\n",
    "\n",
    "### **5.10 Contenerización con Docker**\n",
    "\n",
    "Se crearon Dockerfiles para contenerizar:\n",
    "\n",
    "- **API FastAPI:** Incluye el servidor de la API y todas sus dependencias.\n",
    "\n",
    "- **Aplicación Streamlit:** Incluye la interfaz de usuario y sus dependencias.\n",
    "\n",
    "La contenerización asegura que el sistema se pueda desplegar de manera consistente en diferentes entornos, resolviendo problemas de compatibilidad y dependencias.\n",
    "\n",
    "### **5.11 Despliegue con Docker Compose**\n",
    "\n",
    "Se utilizó Docker Compose para orquestar el despliegue de los microservicios:\n",
    "\n",
    "- Definición de los servicios de la API y la interfaz.\n",
    "- Configuración de una red compartida para permitir la comunicación entre los servicios.\n",
    "- Facilitación del despliegue y escalado del sistema.\n",
    "\n",
    "Este enfoque permite desplegar el sistema completo con un solo comando, simplificando la puesta en producción y el mantenimiento.\n",
    "\n",
    "## **6. Resultados**\n",
    "\n",
    "El modelo XGBoost entrenado alcanzó una precisión del **84%** en el conjunto de prueba, superando a los otros modelos evaluados. A continuación se presenta la métrica de nustro mejor modelo\n",
    "\n",
    "**Matriz de Confusión del Modelo XGBoost:**\n",
    "\n",
    "\n",
    "IMAGEN PENDIENTE\n",
    "\n",
    "Los resultados indican que el modelo XGBoost tiene una alta capacidad para distinguir entre las tres clases de resultados, con mejoras significativas en comparación con los modelos de referencia.\n",
    "\n",
    "Además, las probabilidades estimadas por el modelo permiten entender la confianza en cada predicción, lo cual es valioso para aplicaciones prácticas como análisis deportivos o decisiones de apuestas.\n",
    "\n",
    "## **7. Conclusiones**\n",
    "\n",
    "Este proyecto demuestra la eficacia de utilizar un modelo XGBoost optimizado para predecir los resultados de los partidos de La Liga Española. La integración de herramientas de MLOps como Prefect y MLflow facilitó el desarrollo, seguimiento y despliegue del modelo, garantizando reproducibilidad y mantenibilidad.\n",
    "\n",
    "La arquitectura de microservicios contenerizada y orquestada con Docker Compose proporciona un sistema escalable y portátil, que puede ser desplegado en diferentes entornos con facilidad. La interfaz de usuario desarrollada con Streamlit permite que los usuarios no técnicos interactúen con el modelo y exploren las predicciones.\n",
    "\n",
    "Durante el desarrollo, tuvimos diferentes problemas que logramos resolver. Tuvimos problemas con el training pipeline al implementar el flujo de trabajo; la orquestación de tareas con Prefect requirió de diversos intentos para asegurar que todas las etapas—desde la actualización del dataset y preprocesamiento de datos hasta el entrenamiento y registro del modelo—funcionaran de manera cohesiva. Además, en el backend, encontramos complicaciones al importar el modelo champion desde MLflow. Tuvimos que intentar de diferentes maneras desde el alias del champion hasta el run_id y al final fue esta última que nos ayudó a resolver el problema.\n",
    "\n",
    "Estas experiencias resaltan la importancia de anticipar y planificar para posibles desafíos al trabajar con pipelines complejos y sistemas de gestión de modelos. También nos proporcionan oportunidades para mejorar en futuros proyectos, optimizando los procesos y fortaleciendo la integración entre herramientas.\n",
    "\n",
    "Sin embargo, existen limitaciones que podrían abordarse en trabajos futuros, como la incorporación de datos adicionales (lesiones de jugadores, condiciones climáticas, análisis de sentimiento en redes sociales) que podrían mejorar aún más la precisión del modelo.\n",
    "\n",
    "## **8. Mejoras a Futuro**\n",
    "\n",
    "- **Incorporación de Datos Adicionales:** Agregar variables que capturen factores externos al rendimiento estadístico, como información sobre lesiones, suspensiones, condiciones climáticas y eventos especiales.\n",
    "\n",
    "- **Mejora del Modelo:** Explorar modelos más avanzados, como redes neuronales profundas o modelos híbridos que combinen aprendizaje automático con análisis estadístico tradicional.\n",
    "\n",
    "- **Análisis en Tiempo Real:** Adaptar el sistema para incorporar datos en tiempo real, permitiendo actualizaciones más frecuentes y predicciones más precisas.\n",
    "\n",
    "- **Implementación en la Nube:** Desplegar el sistema en plataformas de nube como AWS, Azure o Google Cloud, aprovechando servicios como Kubernetes para una gestión más avanzada de los contenedores.\n",
    "\n",
    "- **Optimización de la Interfaz de Usuario:** Mejorar la interfaz gráfica para incluir más visualizaciones interactivas y opciones de personalización.\n",
    "\n",
    "- **Integración Continua y Despliegue Continuo (CI/CD):** Implementar pipelines de CI/CD para automatizar las pruebas, el despliegue y las actualizaciones del sistema.\n",
    "\n",
    "\n",
    "\n",
    "## **9. Fuentes**\n",
    "\n",
    "1. **FBref:** [https://fbref.com/es/comps/12/La-Liga-Stats](https://fbref.com/es/comps/12/La-Liga-Stats)\n",
    "\n",
    "2. **Documentación de XGBoost:** [https://xgboost.readthedocs.io/](https://xgboost.readthedocs.io/)\n",
    "\n",
    "3. **Documentación de MLflow:** [https://mlflow.org/docs/latest/index.html](https://mlflow.org/docs/latest/index.html)\n",
    "\n",
    "4. **Documentación de Prefect:** [https://docs.prefect.io/](https://docs.prefect.io/)\n",
    "\n",
    "5. **Documentación de FastAPI:** [https://fastapi.tiangolo.com/es/](https://fastapi.tiangolo.com/es/)\n",
    "\n",
    "6. **Documentación de Streamlit:** [https://docs.streamlit.io/](https://docs.streamlit.io/)\n",
    "\n",
    "7. **Documentación de Docker:** [https://docs.docker.com/](https://docs.docker.com/)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
