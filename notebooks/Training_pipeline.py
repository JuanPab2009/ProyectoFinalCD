# Importamos las librerias
import pandas as pd
import re
import pickle
import dagshub
import pathlib
from mlflow.metrics import precision_score, recall_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from prefect import task, flow
from mlflow.tracking import MlflowClient
from hyperopt import fmin, tpe, hp, Trials, STATUS_OK
from hyperopt.pyll import scope
from sklearn.metrics import accuracy_score, precision_score, recall_score
import mlflow
import mlflow.xgboost
import xgboost as xgb
from xgboost import DMatrix

# Definimos el primer task que es actualizar el dataset
@task(name="Actualilzar dataset")
def actualizar_dataset(file_path,jornada_actual) -> pd.DataFrame:
    jornada = jornada_actual -1
    url = "https://fbref.com/es/comps/12/horario/Resultados-y-partidos-en-La-Liga"
    tables = pd.read_html(url)
    df = tables[0]
    # seleccionamos las variables
    df = df[['Sem.', 'Día', 'Fecha', 'Local', 'Visitante', 'Marcador']]
    # Filtramos por jornada
    df = df[df["Sem."] == jornada]
    # Obtenemos el marcador
    df[['GF', 'GC']] = df['Marcador'].str.split('–', expand=True)
    df['GF'] = df['GF'].astype(int)
    df['GC'] = df['GC'].astype(int)
    df.drop(columns=['Marcador'], inplace=True)
    ## Hacemos la columna fecha del formato correspondiente
    df["Fecha"] = pd.to_datetime(df["Fecha"], errors='coerce')
    df["Fecha"] = df["Fecha"].dt.strftime('%Y-%m-%d')
    # Hacemos el encoding de los días
    dias_map = {
        'Lun': 1,
        'Mar': 2,
        'Mié': 3,
        'Jue': 4,
        'Vie': 5,
        'Sáb': 6,
        'Dom': 7
    }
    df["Día"] = df["Día"].map(dias_map)
    # Agregamos la columnda de sede
    df["Sedes"] = 1
    # Renombramos las columnas
    df = df[["Fecha", "Día", "Sedes", "Visitante", "Local", "GF", "GC"]]
    df = df.rename(columns={"Local": "Anfitrion", "Visitante": "Adversario"})
    # Duplicamos el dataframe e invertimos las columnas para hacer la concatenacion
    df_2 = df.copy()
    df_2 = df_2.rename(columns={"Adversario": "Anfitrion", "Anfitrion": "Adversario", "GF": "GC", "GC": "GF"})
    df_2["Sedes"] = 0
    df = pd.concat([df, df_2], ignore_index=True)
    # Agregamos la columna resultado
    df['Resultado'] = df.apply(lambda row: 3 if row['GF'] > row['GC'] else (2 if row['GF'] == row['GC'] else 1), axis=1)
    # Cambiamos el tipo de dato
    df["Día"] = df["Día"].astype(int)
    ### Estadisticas básicas
    url = "https://fbref.com/es/comps/12/Estadisticas-de-La-Liga"
    tables = pd.read_html(url)
    df_basic = tables[0]
    df_basic = df_basic[
        ['RL', 'Equipo', 'PG', 'PE', 'PP', 'GF', 'GC', 'xG', 'xGA', 'Últimos 5', 'Máximo Goleador del Equipo']]
    df_basic['Máximo Goleador del Equipo'] = df_basic['Máximo Goleador del Equipo'].apply(
        lambda x: int(re.search(r'\b(\d+)\b', x).group(1)) if re.search(r'\b(\d+)\b', x) else None)

    df_basic['Últimos 5'] = df_basic['Últimos 5'].apply(lambda resultados: sum(
        [3 if resultado == 'PG' else (1 if resultado == 'PE' else 0) for resultado in resultados.split()]))
    ### Estadisticas de Ofensiva
    url = "https://fbref.com/es/comps/12/Estadisticas-de-La-Liga"
    tables = pd.read_html(url)
    df_ataque = tables[2]
    df_ataque = df_ataque.drop(["Tiempo Jugado", "Expectativa", 'Por 90 Minutos'], axis=1)
    df_ataque.columns = df_ataque.columns.droplevel(level=0)
    df_ataque = df_ataque[['Equipo', 'Edad', 'Pos.', 'Ass', 'TPint', 'PrgC', 'PrgP']]
    ##### Disparos
    url = "https://fbref.com/es/comps/12/Estadisticas-de-La-Liga"
    tables = pd.read_html(url)
    df_disparos = tables[8]
    df_disparos.columns = df_disparos.columns.droplevel(level=0)
    df_disparos = df_disparos[['Equipo', '% de TT', 'Dist']]
    df_ataque = pd.merge(df_ataque, df_disparos, left_on='Equipo', right_on='Equipo', how='left')
    ##### Pases
    url = "https://fbref.com/es/comps/12/Estadisticas-de-La-Liga"
    tables = pd.read_html(url)
    df_pases = tables[10]
    df_pases = df_pases.drop(["Cortos", "Medios", 'Largos', 'Expectativa'], axis=1)
    df_pases.columns = df_pases.columns.droplevel(level=0)
    df_pases = df_pases[['Equipo', '% Cmp', 'Dist. tot.']]
    df_ataque = pd.merge(df_ataque, df_pases, left_on='Equipo', right_on='Equipo', how='left')
    ### Estadisticas de defensa
    url = "https://fbref.com/es/comps/12/Estadisticas-de-La-Liga"
    tables = pd.read_html(url)
    df_porteria = tables[4]
    df_porteria = df_porteria.drop(["Tiempo Jugado", "Tiros penales"], axis=1)
    df_porteria.columns = df_porteria.columns.droplevel(level=0)
    df_porteria = df_porteria[['Equipo', 'GC', 'DaPC', 'Salvadas', 'PaC']]
    url = "https://fbref.com/es/comps/12/Estadisticas-de-La-Liga"
    tables = pd.read_html(url)
    df_defensa = tables[16]
    df_defensa = df_defensa.drop(['Desafíos'], axis=1)
    df_defensa.columns = df_defensa.columns.droplevel(level=0)
    df_defensa = df_defensa[['Equipo', 'TklG', 'Int', 'Err']]
    df_final = pd.merge(df_ataque, df_defensa, left_on='Equipo', right_on='Equipo', how='left')
    df_final = pd.merge(df_final, df_basic, left_on='Equipo', right_on='Equipo', how='left')
    df_opp = df_final.copy()
    df_tm = df_final.copy()
    # Renombramos las columnas
    columns_to_rename = ['Edad', 'Pos.', 'Ass', 'TPint', 'PrgC', 'PrgP', '% de TT',
                         'Dist', '% Cmp', 'Dist. tot.', 'TklG', 'Int', 'Err', 'RL', 'PG', 'PE',
                         'PP', 'GF', 'GC', 'xG', 'xGA', 'Últimos 5',
                         'Máximo Goleador del Equipo']
    new_column_names_tm = [f"{col}(tm)" for col in columns_to_rename]
    df_tm.rename(columns=dict(zip(columns_to_rename, new_column_names_tm)), inplace=True)
    columns_to_rename = ['Edad', 'Pos.', 'Ass', 'TPint', 'PrgC', 'PrgP', '% de TT',
                         'Dist', '% Cmp', 'Dist. tot.', 'TklG', 'Int', 'Err', 'RL', 'PG', 'PE',
                         'PP', 'GF', 'GC', 'xG', 'xGA', 'Últimos 5',
                         'Máximo Goleador del Equipo']
    new_column_names_opp = [f"{col}(opp)" for col in columns_to_rename]
    df_opp.rename(columns=dict(zip(columns_to_rename, new_column_names_opp)), inplace=True)
    df = pd.merge(df, df_opp, left_on='Adversario', right_on='Equipo', how='left')
    df = pd.merge(df, df_tm, left_on='Anfitrion', right_on='Equipo', how='left')
    df = df.drop(['Equipo_x', 'Equipo_y'], axis=1)
    # Nombre del archivo Excel y de la hoja
    file_path = 'LaLiga Dataset 2023-2024.xlsx'

    df_existente = pd.read_excel(file_path)

    df = pd.concat([df_existente, df], ignore_index=True)
    df.to_excel(file_path, index=False)

    return df

# Definimos el segundo task que es preparar los datos para las predicciones
@task(name="Preparar Datos para Predicciones")
def preparar_datos_prediccion(jornada_actual: int) -> pd.DataFrame:
    jornada = jornada_actual

    url = "https://fbref.com/es/comps/12/horario/Resultados-y-partidos-en-La-Liga"
    tables = pd.read_html(url)
    df = tables[0]
    # seleccionamos las variables
    df = df[['Sem.', 'Día', 'Fecha', 'Local', 'Visitante']]
    ## Hacemos la columna fecha del formato correspondiente
    df["Fecha"] = pd.to_datetime(df["Fecha"])
    # Hacemos el encoding de los días
    dias_map = {
        'Lun': 1,
        'Mar': 2,
        'Mié': 3,
        'Jue': 4,
        'Vie': 5,
        'Sáb': 6,
        'Dom': 7
    }
    df["Día"] = df["Día"].map(dias_map)
    # Filtramos por jornada
    df = df[df["Sem."] == jornada]
    # Agregamos la columnda de sede
    df["Sedes"] = 1
    # Renombramos las columnas
    df = df[["Día", "Sedes", "Visitante", "Local"]]
    df = df.rename(columns={"Local": "Anfitrion", "Visitante": "Adversario"})
    # Duplicamos el dataframe e invertimos las columnas para hacer la concatenacion
    df_2 = df.copy()
    df_2 = df_2.rename(columns={"Adversario": "Anfitrion", "Anfitrion": "Adversario"})
    df_2["Sedes"] = 0
    df = pd.concat([df, df_2], ignore_index=True)
    df["Día"] = df["Día"].astype(int)
    ### Estadisticas básicas
    url = "https://fbref.com/es/comps/12/Estadisticas-de-La-Liga"
    tables = pd.read_html(url)
    df_basic = tables[0]
    df_basic = df_basic[
        ['RL', 'Equipo', 'PG', 'PE', 'PP', 'GF', 'GC', 'xG', 'xGA', 'Últimos 5', 'Máximo Goleador del Equipo']]
    df_basic['Máximo Goleador del Equipo'] = df_basic['Máximo Goleador del Equipo'].apply(
        lambda x: int(re.search(r'\b(\d+)\b', x).group(1)) if re.search(r'\b(\d+)\b', x) else None)
    df_basic['Últimos 5'] = df_basic['Últimos 5'].apply(lambda resultados: sum(
        [3 if resultado == 'PG' else (1 if resultado == 'PE' else 0) for resultado in resultados.split()]))
    ### Estadisticas de Ofensiva
    url = "https://fbref.com/es/comps/12/Estadisticas-de-La-Liga"
    tables = pd.read_html(url)
    df_ataque = tables[2]
    df_ataque = df_ataque.drop(["Tiempo Jugado", "Expectativa", 'Por 90 Minutos'], axis=1)
    df_ataque.columns = df_ataque.columns.droplevel(level=0)
    df_ataque = df_ataque[['Equipo', 'Edad', 'Pos.', 'Ass', 'TPint', 'PrgC', 'PrgP']]
    # Disparos
    url = "https://fbref.com/es/comps/12/Estadisticas-de-La-Liga"
    tables = pd.read_html(url)
    df_disparos = tables[8]
    df_disparos.columns = df_disparos.columns.droplevel(level=0)
    df_disparos = df_disparos[['Equipo', '% de TT', 'Dist']]
    df_ataque = pd.merge(df_ataque, df_disparos, left_on='Equipo', right_on='Equipo', how='left')
    # Pases
    url = "https://fbref.com/es/comps/12/Estadisticas-de-La-Liga"
    tables = pd.read_html(url)
    df_pases = tables[10]
    df_pases = df_pases.drop(["Cortos", "Medios", 'Largos', 'Expectativa'], axis=1)
    df_pases.columns = df_pases.columns.droplevel(level=0)
    df_pases = df_pases[['Equipo', '% Cmp', 'Dist. tot.']]
    df_ataque = pd.merge(df_ataque, df_pases, left_on='Equipo', right_on='Equipo', how='left')
    ### Estadisticas de defensa
    url = "https://fbref.com/es/comps/12/Estadisticas-de-La-Liga"
    tables = pd.read_html(url)
    df_porteria = tables[4]
    df_porteria = df_porteria.drop(["Tiempo Jugado", "Tiros penales"], axis=1)
    df_porteria.columns = df_porteria.columns.droplevel(level=0)
    df_porteria = df_porteria[['Equipo', 'GC', 'DaPC', 'Salvadas', 'PaC']]
    url = "https://fbref.com/es/comps/12/Estadisticas-de-La-Liga"
    tables = pd.read_html(url)
    df_defensa = tables[16]
    df_defensa = df_defensa.drop(['Desafíos'], axis=1)
    df_defensa.columns = df_defensa.columns.droplevel(level=0)
    df_defensa = df_defensa[['Equipo', 'TklG', 'Int', 'Err']]
    df_final = pd.merge(df_ataque, df_defensa, left_on='Equipo', right_on='Equipo', how='left')
    df_final = pd.merge(df_final, df_basic, left_on='Equipo', right_on='Equipo', how='left')
    df_opp = df_final.copy()
    df_tm = df_final.copy()
    # Renombramos las columnas
    columns_to_rename = ['Edad', 'Pos.', 'Ass', 'TPint', 'PrgC', 'PrgP', '% de TT',
                         'Dist', '% Cmp', 'Dist. tot.', 'TklG', 'Int', 'Err', 'RL', 'PG', 'PE',
                         'PP', 'GF', 'GC', 'xG', 'xGA', 'Últimos 5',
                         'Máximo Goleador del Equipo']
    new_column_names_tm = [f"{col}(tm)" for col in columns_to_rename]
    df_tm.rename(columns=dict(zip(columns_to_rename, new_column_names_tm)), inplace=True)
    columns_to_rename = ['Edad', 'Pos.', 'Ass', 'TPint', 'PrgC', 'PrgP', '% de TT',
                         'Dist', '% Cmp', 'Dist. tot.', 'TklG', 'Int', 'Err', 'RL', 'PG', 'PE',
                         'PP', 'GF', 'GC', 'xG', 'xGA', 'Últimos 5',
                         'Máximo Goleador del Equipo']
    new_column_names_opp = [f"{col}(opp)" for col in columns_to_rename]
    df_opp.rename(columns=dict(zip(columns_to_rename, new_column_names_opp)), inplace=True)
    df = pd.merge(df, df_opp, left_on='Adversario', right_on='Equipo', how='left')
    df = pd.merge(df, df_tm, left_on='Anfitrion', right_on='Equipo', how='left')
    df = df.drop(['Equipo_x', 'Equipo_y'], axis=1)
    df_prediccion = df

    return df_prediccion
@task(name="Cargar y Procesar Dataset")
def cargar_procesar_dataset(df):

    X = df[['Día','Sedes','Edad(opp)','Pos.(opp)', 'Ass(opp)', 'TPint(opp)',
      'PrgC(opp)', 'PrgP(opp)','% de TT(opp)', 'Dist(opp)', '% Cmp(opp)', 'Dist. tot.(opp)','TklG(opp)', 'Int(opp)',
      'Err(opp)', 'RL(opp)', 'PG(opp)', 'PE(opp)','PP(opp)', 'GF(opp)', 'GC(opp)', 'xG(opp)', 'xGA(opp)','Últimos 5(opp)',
      'Máximo Goleador del Equipo(opp)', 'Edad(tm)', 'Pos.(tm)', 'Ass(tm)', 'TPint(tm)', 'PrgC(tm)', 'PrgP(tm)',
      '% de TT(tm)', 'Dist(tm)', '% Cmp(tm)', 'Dist. tot.(tm)', 'TklG(tm)','Int(tm)', 'Err(tm)', 'RL(tm)', 'PG(tm)',
      'PE(tm)', 'PP(tm)', 'GF(tm)','GC(tm)', 'xG(tm)', 'xGA(tm)', 'Últimos 5(tm)','Máximo Goleador del Equipo(tm)']]
    y = df['Resultado']

    # Ajustar las etiquetas de las clases en y
    y = y - 1

    # Dividimos en conjuntos de entrenamiento y prueba
    X_train, X_val, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)

    # Escalar los datos
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_val)

    # Guardamos el scaler
    pathlib.Path("models").mkdir(exist_ok=True)
    with open("models/scaler.pkl", "wb") as f_out:
        pickle.dump(scaler, f_out)

    return X_train, X_test, y_train, y_test

# Creamos el task para entrenar los modelos
@task(name = "Hyper-Parameter Tunning")
def hyper_parameter_tunning(X_train, X_test, y_train, y_test):
    dtrain = xgb.DMatrix(X_train, label=y_train)
    dtest = xgb.DMatrix(X_test, label=y_test)

    def objective_xgb(params):
        with mlflow.start_run(nested=True):
            mlflow.set_tag("model_family", "XGBoost-prefect")
            mlflow.log_params(params)

            params['objective'] = 'multi:softprob'
            params['num_class'] = 3  # Tres clases
            params['eval_metric'] = 'mlogloss'

            # Entrenamos el modelo
            model = xgb.train(
                params=params,
                dtrain=dtrain,
                num_boost_round=params.get('n_estimators', 100)
            )

            # Realizamos las predicciones
            y_pred = model.predict(dtest)

            # Calculamos las métricas
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, average='weighted')
            recall = recall_score(y_test, y_pred, average='weighted')

            # Registramos las métricas en MLflow
            mlflow.log_metric("accuracy", accuracy)
            mlflow.log_metric("precision", precision)
            mlflow.log_metric("recall", recall)

            # Registramos el modelo en MLflow
            mlflow.xgboost.log_model(model, artifact_path="model-xgb")
            mlflow.log_artifact("models/scaler.pkl", artifact_path="scaler")

            # La función objetivo devuelve la pérdida como negativa de la precisión
            return {'loss': -accuracy, 'status': STATUS_OK}

    # Espacio de búsqueda para la optimización de hiperparámetros
    search_space_xgb = {
        'n_estimators': scope.int(hp.quniform('n_estimators', 100, 500, 1)),
        'max_depth': scope.int(hp.quniform('max_depth', 3, 10, 1)),
        'learning_rate': hp.loguniform('learning_rate', -3, 0),
        'subsample': hp.uniform('subsample', 0.5, 1.0),
        'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),
        'gamma': hp.uniform('gamma', 0, 5),
        'min_child_weight': scope.int(hp.quniform('min_child_weight', 1, 10, 1))
    }

    # Ejecutamos la optimización
    # Ejecutamos la optimización
    with mlflow.start_run(run_name="XGBoost Hyper-parameter Optimization"):
        best_params_xgb = fmin(
            fn=objective_xgb,
            space=search_space_xgb,
            algo=tpe.suggest,
            max_evals=10,
            trials=Trials()
        )

        # Convertir parámetros al formato adecuado
        best_params_xgb['n_estimators'] = int(best_params_xgb['n_estimators'])
        best_params_xgb['max_depth'] = int(best_params_xgb['max_depth'])
        best_params_xgb['min_child_weight'] = int(best_params_xgb['min_child_weight'])
        mlflow.log_params(best_params_xgb)

        return best_params_xgb

# Creamos el task para registrar modelos en el model registry
@task(name="Train best model")
def train_best_model(X_train, X_test, y_train, y_test, best_params_xgb) -> None:
    with mlflow.start_run(run_name="Best XGBoost model ever"):
        dtrain = xgb.DMatrix(X_train, label=y_train)
        dtest = xgb.DMatrix(X_test, label=y_test)

        # Añadimos parámetros necesarios para multiclase
        best_params_xgb['objective'] = 'multi:softprob'
        best_params_xgb['num_class'] = 3  # Tres clases
        best_params_xgb['eval_metric'] = 'mlogloss'

        best_model_xgb = xgb.train(
            params=best_params_xgb,
            dtrain=dtrain,
            num_boost_round=best_params_xgb.get('n_estimators', 100)
        )

        y_pred_xgb = best_model_xgb.predict(dtest)
        accuracy_xgb = accuracy_score(y_test, y_pred_xgb)
        precision_xgb = precision_score(y_test, y_pred_xgb, average='weighted')
        recall_xgb = recall_score(y_test, y_pred_xgb, average='weighted')

        mlflow.log_metric("accuracy", accuracy_xgb)
        mlflow.log_metric("precision", precision_xgb)
        mlflow.log_metric("recall", recall_xgb)

    return None


# Creamos el task para comparar los modelos y asignar los alías
@task(name="Comparar Modelos y Asignar Alias")
def register_best_model():
    client = MlflowClient()

    # Declaramos el experimento en el que estamos trabajando
    experiment_name = "final-prefect-experiment"

    experiment = client.get_experiment_by_name(experiment_name)

    # Buscamos las dos mejores ejecuciones en base al accuracy
    top_runs = mlflow.search_runs(
        experiment_ids=[experiment.experiment_id],
        order_by=["metrics.accuracy DESC"],  # Cambia a ASC si buscas minimizar
        max_results=2  # Recuperar las dos mejores
    )

    # Obtenemos los IDs de las mejores ejecuciones
    champion_run = top_runs.iloc[0]
    challenger_run = top_runs.iloc[1]

    # Obtenemos los IDs de las ejecuciones
    champion_run_id = champion_run.run_id
    challenger_run_id = challenger_run.run_id

    champion_model_uri = f"runs:/{champion_run_id}/model"
    challenger_model_uri = f"runs:/{challenger_run_id}/model"

    # Declaramos el nombre del modelo registrado
    model_name = "final-prefect-model"

    # Registramos el Champion
    champion_model_version = mlflow.register_model(champion_model_uri, model_name)
    client.set_registered_model_alias(model_name, "champion", champion_model_version.version)

    # Registramos el Challenger
    challenger_model_version = mlflow.register_model(challenger_model_uri, model_name)
    client.set_registered_model_alias(model_name, "challenger", challenger_model_version.version)

# Definimos el flow principal
@flow(name="Pipeline de Entrenamiento y Registro de Modelos")
def pipeline_entrenamiento(jornada_actual: int):
    file_path ="LaLiga Dataset 2023-2024.xlsx"
    jornada_actual = 15
    # Inicializamos MLflow y DagsHub
    dagshub.init(url="https://dagshub.com/JuanPab2009/ProyectoFinalCD", mlflow=True)
    MLFLOW_TRACKING_URI = mlflow.get_tracking_uri()
    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
    mlflow.set_experiment(experiment_name="final-prefect-experiment")

    # Ejecutar las tareas de flujo
    print("Ejecutando tarea: Actualizar dataset")
    df = actualizar_dataset(file_path,jornada_actual)

    print("Ejecutando tarea: Preparar datos para prediccion")
    df_prediccion = preparar_datos_prediccion(jornada_actual)

    # Cargamos y procesamos el dataset
    print("Ejecutando tarea: Cargando y procesando el dataset")
    X_train, X_test, y_train, y_test = cargar_procesar_dataset(df)

    print("Ejecutando tarea: hyper-parameter tuning")
    best_params_xgb = hyper_parameter_tunning(X_train, X_test, y_train, y_test)

    print("Ejecutando tarea: train best models")
    train_best_model(X_train, X_test, y_train, y_test, best_params_xgb)

    print("Ejecutando tarea: register best model")
    register_best_model()

    print("Flujo completado con éxito.")


if __name__ == "__main__":
    pipeline_entrenamiento(jornada_actual=15)
